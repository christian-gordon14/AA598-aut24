{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework 2 libs\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # for the project\n",
    "\n",
    "from aa598.hw2_helper import simulate_dynamics\n",
    "import cvxpy as cp\n",
    "from cbfax.dynamics import *\n",
    "\n",
    "# Homework 1 libs\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import aa598.hw1_helper as hw1_helper\n",
    "\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=False) # set to False if latex is not set up on your computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = DynamicallyExtendedSimpleCar() # robot dynamics\n",
    "human = DynamicallyExtendedSimpleCar() # human dynamics\n",
    "\n",
    "@jax.jit\n",
    "def obstacle_constraint(state, obstacle, radius):\n",
    "    return jnp.linalg.norm(state[:2] - obstacle[:2]) - radius\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_horizon = 25\n",
    "num_time_steps = 30\n",
    "num_sqp_iterations = 15\n",
    "dt = 0.1\n",
    "t = 0. # this doesn't affect anything, but a value is needed \n",
    "radius = 1. # minimum collision distance\n",
    "\n",
    "v_max = 1.5\n",
    "v_min = 0.\n",
    "acceleration_max = 1.0\n",
    "acceleration_min = -1.0\n",
    "steering_max = 0.3\n",
    "steering_min = -0.3\n",
    "\n",
    "human_control_prediction_noise_limit = 0.25\n",
    "human_control_prediction_variance = 0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = cp.Variable([planning_horizon+1, robot.state_dim])  # cvx variable for states\n",
    "us = cp.Variable([planning_horizon, robot.control_dim])  # cvx variable for controls\n",
    "slack = cp.Variable(1) # slack variable to make sure the problem is feasible\n",
    "As = [cp.Parameter([robot.state_dim, robot.state_dim]) for _ in range(planning_horizon)]  # parameters for linearized dynamics\n",
    "Bs = [cp.Parameter([robot.state_dim, robot.control_dim]) for _ in range(planning_horizon)] # parameters for linearized dynamics\n",
    "Cs = [cp.Parameter([robot.state_dim]) for _ in range(planning_horizon)] # parameters for linearized dynamics\n",
    "\n",
    "Gs = [cp.Parameter([robot.state_dim]) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "hs = [cp.Parameter(1) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "\n",
    "xs_previous = cp.Parameter([planning_horizon+1, robot.state_dim]) # parameter for previous solution\n",
    "us_previous = cp.Parameter([planning_horizon, robot.control_dim]) # parameter for previous solution\n",
    "initial_state = cp.Parameter([robot.state_dim]) # parameter for current robot state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = 0.2 # coefficient for control effort\n",
    "beta2 = 2. # coefficient for progress\n",
    "beta3 = 10. # coefficient for trust region\n",
    "slack_penalty = 1000. # coefficient for slack variable\n",
    "markup = 1.0\n",
    "\n",
    "objective = beta2 * (xs[-1,2]**2 + xs[-1,1]**2 - xs[-1,0]) + beta3 * (cp.sum_squares(xs - xs_previous) + cp.sum_squares(us - us_previous)) + slack_penalty * slack**2\n",
    "constraints = [xs[0] == initial_state, slack >= 0] # initial state and slack constraint\n",
    "for t in range(planning_horizon):\n",
    "    objective += beta1 * cp.sum_squares(us[t]) * markup**t\n",
    "    constraints += [xs[t+1] == As[t] @ xs[t] + Bs[t] @ us[t] + Cs[t]] # dynamics constraint\n",
    "    constraints += [xs[t,-1] <= v_max, xs[t,-1] >= v_min, us[t,0] <= acceleration_max, us[t,0] >= acceleration_min, us[t,1] <= steering_max, us[t,1] >= steering_min] # control limit constraints\n",
    "    constraints += [Gs[t] @ xs[t] + hs[t] >= -slack] # linearized collision avoidance constraint\n",
    "constraints += [xs[planning_horizon,-1] <= v_max, xs[planning_horizon,-1] >= v_min, Gs[planning_horizon] @ xs[planning_horizon] + hs[planning_horizon] >= 0] # constraints for last planning horizon step\n",
    "prob = cp.Problem(cp.Minimize(objective), constraints) # construct problem\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial states\n",
    "robot_state = jnp.array([-3.0, -0., 0., 1.])  # robot starting state\n",
    "human_state = jnp.array([-1., -2., jnp.pi/2, 1.]) # human starting state\n",
    "\n",
    "robot_trajectory = [robot_state] # list to collect robot's state as it replans\n",
    "human_trajectory = [human_state] # list to collect humans's state\n",
    "robot_control_list = []  # list to collect robot's constrols as it replans\n",
    "robot_trajectory_list = [] # list to collect robot's planned trajectories\n",
    "\n",
    "# initial robot planned state and controls\n",
    "previous_controls = jnp.zeros([planning_horizon, robot.control_dim]) # initial guess for robot controls\n",
    "previous_states =  simulate_dynamics(robot, robot_state, previous_controls, dt) # initial guess for robot states\n",
    "xs_previous.value = np.array(previous_states) # set xs_previous parameter value\n",
    "us_previous.value = np.array(previous_controls) # set us_previous parameter value \n",
    "\n",
    "# jit the linearize dynamics and constraint functions to make it run faster\n",
    "linearize_dynamics = jax.jit(lambda states, controls, ti: jax.vmap(linearize, [None, 0, 0, None])(lambda s, c, t: robot.discrete_step(s, c, t, dt), states, controls, ti))\n",
    "linearize_obstacle = jax.jit(lambda states, controls, radius: jax.vmap(jax.grad(obstacle_constraint), [0, 0, None])(states, controls, radius))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep: 0\n",
      "timestep: 1\n",
      "timestep: 2\n",
      "timestep: 3\n",
      "timestep: 4\n",
      "timestep: 5\n",
      "timestep: 6\n",
      "timestep: 7\n",
      "timestep: 8\n",
      "timestep: 9\n",
      "timestep: 10\n",
      "timestep: 11\n",
      "timestep: 12\n",
      "timestep: 13\n",
      "timestep: 14\n",
      "timestep: 15\n",
      "timestep: 16\n",
      "timestep: 17\n",
      "timestep: 18\n",
      "timestep: 19\n",
      "timestep: 20\n",
      "timestep: 21\n",
      "timestep: 22\n",
      "timestep: 23\n",
      "timestep: 24\n",
      "timestep: 25\n",
      "timestep: 26\n",
      "timestep: 27\n",
      "timestep: 28\n",
      "timestep: 29\n"
     ]
    }
   ],
   "source": [
    "solver = cp.CLARABEL\n",
    "\n",
    "for t in range(num_time_steps):\n",
    "    print(\"timestep: %i\"% t)\n",
    "    initial_state.value = np.array(robot_state)\n",
    "    # simulate human future trajectory, assuming some noisy behavior\n",
    "    noisy_human_control = jnp.clip(jnp.array(np.random.randn(planning_horizon, human.control_dim) * human_control_prediction_variance), -human_control_prediction_noise_limit, human_control_prediction_noise_limit)\n",
    "    human_future = simulate_dynamics(human, human_state, noisy_human_control, dt)\n",
    "    \n",
    "    for i in range(num_sqp_iterations):\n",
    "        # As_value, Bs_value, Cs_value = jax.vmap(linearize, [None, 0, 0, None])(lambda s, c, t: robot.discrete_step(s, c, t, dt), previous_states[:-1], previous_controls, t)\n",
    "        As_value, Bs_value, Cs_value = linearize_dynamics( previous_states[:-1], previous_controls, t)\n",
    "        # Gs_value = jax.vmap(jax.grad(obstacle_constraint), [0, 0, None])(previous_states, human_future, radius)\n",
    "        Gs_value = linearize_obstacle(previous_states, human_future, radius)\n",
    "        hs_value = jax.vmap(obstacle_constraint, [0, 0, None])(previous_states, human_future, radius) - jax.vmap(jnp.dot, [0, 0])(Gs_value, previous_states)\n",
    "\n",
    "        for i in range(planning_horizon):\n",
    "            As[i].value = np.array(As_value[i])\n",
    "            Bs[i].value = np.array(Bs_value[i])\n",
    "            Cs[i].value = np.array(Cs_value[i])\n",
    "            Gs[i].value = np.array(Gs_value[i])\n",
    "            hs[i].value = np.array(hs_value[i:i+1])\n",
    "        Gs[planning_horizon].value = np.array(Gs_value[planning_horizon])\n",
    "        hs[planning_horizon].value = np.array(hs_value[planning_horizon:planning_horizon+1])\n",
    "        \n",
    "        result = prob.solve(solver=solver)\n",
    "\n",
    "        # previous_states = xs.value\n",
    "        previous_controls = us.value\n",
    "        previous_states =  simulate_dynamics(robot, robot_state, previous_controls, dt)\n",
    "        xs_previous.value = np.array(previous_states)\n",
    "        us_previous.value = np.array(previous_controls)\n",
    "        \n",
    "    robot_control = previous_controls[0]\n",
    "    robot_control_list.append(robot_control)\n",
    "    # robot takes a step\n",
    "    robot_state = robot.discrete_step(robot_state, robot_control, 0., dt)\n",
    "    robot_trajectory.append(robot_state)\n",
    "    robot_trajectory_list.append(previous_states)\n",
    "\n",
    "    \n",
    "    human_random_control = jnp.clip(jnp.array(np.random.randn( human.control_dim) * human_control_prediction_variance), -human_control_prediction_noise_limit, human_control_prediction_noise_limit)\n",
    "    # human states a step\n",
    "    human_state = human.discrete_step(human_state, human_random_control, 0., dt)\n",
    "    human_trajectory.append(human_state)\n",
    "    \n",
    "robot_trajectory = jnp.stack(robot_trajectory)\n",
    "human_trajectory = jnp.stack(human_trajectory)\n",
    "robot_controls = jnp.stack(robot_control_list)\n",
    "\n",
    "#Project code\n",
    "\n",
    "with open('robot_trajectory_v1.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(robot_trajectory, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821ed9f407d94f95a579d6bdcf1a33c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=14, description='i', max=29), Output()), _dom_classes=('widget-interact'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting\n",
    "@interact(i=(0,num_time_steps-1))\n",
    "def plot(i):\n",
    "    fig, axs = plt.subplots(1,2, figsize=(18,8))\n",
    "    ax = axs[0]\n",
    "    robot_position = robot_trajectory[i, :2]\n",
    "    human_position = human_trajectory[i, :2]\n",
    "    circle1 = plt.Circle(robot_position, radius / 2, color='C0', alpha=0.4)\n",
    "    circle2 = plt.Circle(human_position, radius / 2, color='C1', alpha=0.4)\n",
    "    ax.add_patch(circle1)\n",
    "    ax.add_patch(circle2)\n",
    "    # ax.plot(human_samples[i,:,:,0].T, human_samples[i,:,:,1].T, \"o-\", alpha=0.1, markersize=2, color='C1')\n",
    "    ax.plot(robot_trajectory[:,0], robot_trajectory[:,1], \"o-\", markersize=3, color='C0')\n",
    "    ax.plot(robot_trajectory_list[i][:,0], robot_trajectory_list[i][:,1], \"o-\", markersize=3, color='C2', label=\"planned\")\n",
    "    print(robot_trajectory[i])\n",
    "\n",
    "    ax.plot(human_trajectory[:,0], human_trajectory[:,1], \"o-\", markersize=3, color='C1')\n",
    "    ax.scatter(robot_trajectory[i:i+1,0], robot_trajectory[i:i+1,1], s=30,  color='C0', label=\"Robot\")\n",
    "    ax.scatter(human_trajectory[i:i+1,0], human_trajectory[i:i+1,1], s=30,  color='C1', label=\"Human\")\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_xlim([-4,4])\n",
    "    ax.set_ylim([-3, 2])\n",
    "    ax.axis(\"equal\")\n",
    "\n",
    "    ax.set_title(\"heading=%.2f velocity=%.2f\"%(robot_trajectory[i,2], robot_trajectory[i,3]))\n",
    "    \n",
    "    ax = axs[1]\n",
    "    plt.plot(robot_controls)\n",
    "    plt.scatter([i], robot_controls[i:i+1, 0], label=\"Acceleration\")\n",
    "    plt.scatter([i], robot_controls[i:i+1, 1], label=\"Steering\")\n",
    "    ax.plot(robot_trajectory[:,-1], \"o-\", markersize=3, color='C0', label=\"Velocity\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.9025506  0.8088253  0.735498   0.67337227 0.61558074\n",
      " 0.5718716  0.5298723  0.48635265 0.45573086 0.43023476 0.4100539\n",
      " 0.3609973  0.32961822 0.31166002 0.29682413 0.24794996 0.22135593\n",
      " 0.21091996 0.212036   0.20191258 0.20105538 0.20463185 0.21716012\n",
      " 0.23631659 0.25981542 0.28602886 0.31380352 0.34232852 0.3710388\n",
      " 0.3995453 ]\n"
     ]
    }
   ],
   "source": [
    "with open('robot_trajectory_v1.pickle', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    loaded_data = pickle.load(f)\n",
    "xPositionHuman = loaded_data[:, 0]\n",
    "yPositionHuman = loaded_data[:, 1]\n",
    "headingHuman = loaded_data[:, 2]\n",
    "velocityHuman = loaded_data[:, 3]\n",
    "print(velocityHuman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple MLP model\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, history_length, future_length, hidden_size=32):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # TODO: construct MLP network\n",
    "        self.model = None\n",
    "        #############################\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 8\n",
    "history_length = 10\n",
    "future_length = 5\n",
    "\n",
    "model = MLP(history_length, future_length, hidden_size)\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer = hw1_helper.train(model, optimizer, train_dataloader, criterion, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on a test set. \n",
    "model.eval()\n",
    "test_dataloader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)\n",
    "for (history, future) in test_dataloader:\n",
    "    prediction = model(history)         # Forward pass\n",
    "    loss = criterion(prediction, future)  # Compute loss\n",
    "    \n",
    "# print out test loss\n",
    "print(f'Test Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Visualize prediction on test data\n",
    "index_slider = widgets.IntSlider(value=0, min=0, max=len(test_data)-1, step=1, description='Index:')\n",
    "xlims = [-11, 5]\n",
    "ylims = [-2,2]\n",
    "interact(hw1_helper.plot_data_regression, history=widgets.fixed(history), future=widgets.fixed(future), prediction=widgets.fixed(prediction), index=index_slider, xlims=widgets.fixed(xlims), ylims=widgets.fixed(ylims))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
